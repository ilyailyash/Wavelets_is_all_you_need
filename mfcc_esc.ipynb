{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import webrtcvad\n",
    "from scipy.io import wavfile\n",
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import math\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('/home/ilya/workspace/ESC-50')\n",
    "from utils import ESC50\n",
    "\n",
    "def filter_VAD(filename, frame_duration, frame_length):\n",
    "    sample_rate, data = wavfile.read(filename)\n",
    "    vad = webrtcvad.Vad(3)\n",
    "    data = np.pad(data, int(frame_length // 2), mode='reflect')\n",
    "    frames = librosa.util.frame(data, frame_length, hop_length=frame_length // 4)\n",
    "\n",
    "    frame_seq = []\n",
    "\n",
    "    for i in range(frames.shape[1]):\n",
    "        if(vad.is_speech(frames[:,i].tobytes(), sample_rate)):\n",
    "            frame_seq.append(i)\n",
    "\n",
    "    voiced_frames = np.array(frame_seq)\n",
    "    print('frames shape:', frames.shape, \n",
    "          'voiced_frames shape:', voiced_frames.shape)\n",
    "    \n",
    "    return(voiced_frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = '/home/ilya/workspace/ESC-50/audio/16000/1-137-A-32.wav'\n",
    "# sample_rate, y = wavfile.read(filename)\n",
    "# y = np.array(y,dtype=float)\n",
    "# n_fft = 2048\n",
    "# S = librosa.feature.melspectrogram(y, sr=sample_rate, n_mels=128,\n",
    "#                                    fmax=8000, n_fft=n_fft,\n",
    "#                                    hop_length=n_fft//2)\n",
    "# log_S = librosa.core.power_to_db(S)\n",
    "# mfcc = librosa.feature.mfcc(S=log_S, n_mfcc=13)\n",
    "# delta_mfcc  = librosa.feature.delta(mfcc)\n",
    "# delta2_mfcc = librosa.feature.delta(mfcc, order=2)\n",
    "# np.vstack((mfcc,delta_mfcc,delta2_mfcc)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilya/anaconda3/envs/torch/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2048, 39, 79])\n"
     ]
    }
   ],
   "source": [
    "train_splits = [1,2,3,4]\n",
    "test_split = 5\n",
    "\n",
    "shared_params = {'csv_path': '/home/ilya/workspace/ESC-50/esc50.csv',\n",
    "                 'wav_dir': '/home/ilya/workspace/ESC-50/audio',\n",
    "                 'dest_dir': '/home/ilya/workspace/ESC-50/audio/16000',\n",
    "                 'audio_rate': 16000,\n",
    "                 'only_ESC10': True,\n",
    "                 'pad': 0,\n",
    "                 'normalize': True}\n",
    "\n",
    "train_gen = ESC50(folds=train_splits,\n",
    "                  randomize=True,\n",
    "                  strongAugment=True,\n",
    "                  random_crop=True,\n",
    "                  inputLength=2,\n",
    "                  mix=False,\n",
    "                  frames=True,\n",
    "                  n_fft=2048,\n",
    "                  **shared_params).batch_gen(16)\n",
    "\n",
    "test_gen = ESC50(folds=[test_split],\n",
    "                 randomize=False,\n",
    "                 strongAugment=False,\n",
    "                 random_crop=False,\n",
    "                 inputLength=4,\n",
    "                 mix=False,\n",
    "                 frames=True,\n",
    "                 n_fft=2048,\n",
    "                 **shared_params).batch_gen(2048)\n",
    "\n",
    "eval_inputs, eval_labels = next(test_gen)\n",
    "eval_inputs, eval_labels = torch.Tensor(eval_inputs).cuda(), torch.LongTensor(eval_labels).cuda()\n",
    "print (eval_inputs.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class classifier_mfcc(nn.Module):\n",
    "    def __init__(self, stride=1,padding=1, dilation=1, groups=1):\n",
    "        super(classifier_mfcc, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(39, 15, 3)\n",
    "        self.pool = nn.MaxPool1d(2)\n",
    "        self.conv2 = nn.Conv1d(15,20,3)\n",
    "        self.conv3 = nn.Conv1d(20,25,3)\n",
    "        self.lastpool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc1 = nn.Linear(25,120)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(120,10)\n",
    "    \n",
    "    def forward(self,x):\n",
    "\n",
    "        output = self.pool(self.conv1(x))\n",
    "        output = self.pool(self.conv2(output))\n",
    "        output = self.conv3(output)\n",
    "        output = self.lastpool(output)\n",
    "        output = self.relu(self.fc1(output.squeeze()))\n",
    "        output = self.fc2(output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "classifier_mfcc(\n",
       "  (conv1): Conv1d(39, 15, kernel_size=(3,), stride=(1,))\n",
       "  (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv1d(15, 20, kernel_size=(3,), stride=(1,))\n",
       "  (conv3): Conv1d(20, 25, kernel_size=(3,), stride=(1,))\n",
       "  (lastpool): AdaptiveAvgPool1d(output_size=1)\n",
       "  (fc1): Linear(in_features=25, out_features=120, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=120, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_mfcc = classifier_mfcc()\n",
    "net_mfcc.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('runs/mfcc_log')\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(net_mfcc.parameters(), lr=0.001, momentum=0.9)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.7,patience=100, verbose=True, threshold=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilya/anaconda3/envs/torch/lib/python3.6/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   106: reducing learning rate of group 0 to 4.9000e-04.\n",
      "Epoch   223: reducing learning rate of group 0 to 3.4300e-04.\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "C = 0.07\n",
    "l2 = 0.03\n",
    "best_loss = 100\n",
    "for epoch in range(100):  # loop over the dataset multiple times\n",
    "    \n",
    "    train_gen = ESC50(folds=train_splits,\n",
    "                  randomize=True,\n",
    "                  strongAugment=True,\n",
    "                  random_crop=True,\n",
    "                  inputLength=2,\n",
    "                  mix=False,\n",
    "                  frames=True,\n",
    "                  n_fft=2048,\n",
    "                  **shared_params).batch_gen(256)\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_gen:\n",
    "        # get the inputs\n",
    "        inputs, labels = torch.Tensor(inputs).cuda(), torch.LongTensor(labels).cuda()\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        outputs = net_mfcc(inputs)\n",
    "\n",
    "        _, labels = torch.max(labels, 1)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        scheduler.step(loss)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        if i%100 == 0:\n",
    "            \n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            out_ev = net_mfcc(eval_inputs) \n",
    "            _, labels_2 = torch.max(eval_labels, 1) \n",
    "            loss_ev = criterion(out_ev, labels_2)\n",
    "            \n",
    "            if loss_ev<best_loss:\n",
    "                best_loss = loss_ev\n",
    "                torch.save(net_mfcc.state_dict(),'best_mfcc')\n",
    "                \n",
    "            writer.add_scalar(\"loss_ev\", loss_ev.item())\n",
    "            writer.add_scalar(\"acc_ev\", (out_ev.max(1)[1]==labels_2).float().mean().item())\n",
    "#             print (epoch,i,loss.data,(predicted==labels).float().mean())  \n",
    "            \n",
    "        i+=1\n",
    "#         print (net.wavelet.energy(net.wavelet.weight_lo), net.wavelet.energy(net.wavelet.weight_hi), net.wavelet.lo_Norm.L.grad, loss.data)\n",
    "        \n",
    "        writer.add_scalar(\"loss\", loss.item())\n",
    "        writer.add_scalar(\"acc\", (outputs.max(1)[1]==labels).float().mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
