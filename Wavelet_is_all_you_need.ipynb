{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import math\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from scipy import fft\n",
    "import librosa\n",
    "\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('/home/ilya/workspace/ESC-50')\n",
    "from utils import ESC50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalisation(nn.Module):\n",
    "    def __init__(self,hi,eps=1e-6):\n",
    "        super(Normalisation, self).__init__()\n",
    "        self.L = nn.Parameter(torch.Tensor(1))\n",
    "        self.B = nn.Parameter(torch.Tensor(1))\n",
    "        self.hi = hi\n",
    "        self.eps = eps\n",
    "        self.reset_parameters()\n",
    "        self.Sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        nn.init.uniform_(self.L,-1,1)\n",
    "        nn.init.uniform_(self.B,-1,1)\n",
    "    \n",
    "    def mul_sigmoid(self, weight):\n",
    "        return self.Sigmoid(weight)+0.5\n",
    "    \n",
    "    def add_sigmoid(self, weight):\n",
    "        return self.Sigmoid(weight)-0.5 \n",
    "    \n",
    "    def forward(self, weight):\n",
    "        \n",
    "        if self.hi:\n",
    "            mean = weight.mean(-1)\n",
    "            weight = weight-mean\n",
    "            div = torch.sqrt(weight.pow(2).sum(-1)+self.eps)\n",
    "            normilized_weight = weight/div\n",
    "            normilized_weight = self.mul_sigmoid(self.L)*normilized_weight+self.add_sigmoid(self.B)\n",
    "        else:            \n",
    "            div = torch.sqrt(weight.pow(2).sum(-1)+self.eps)\n",
    "            normilized_weight = weight/div\n",
    "            normilized_weight = self.mul_sigmoid(self.L)*normilized_weight \n",
    "\n",
    "        return normilized_weight\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Wavelet(nn.Module):\n",
    "    def __init__(self, num_layers, kernel_size, stride=1,\n",
    "                 padding=1, dilation=1, groups=1, disp=False, norm=False):\n",
    "        super(Wavelet, self).__init__()\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.dilation = dilation\n",
    "        self.groups = groups\n",
    "        self.disp = disp\n",
    "        self.norm = norm\n",
    "        \n",
    "        if self.norm:\n",
    "            self.hi_Norm = Normalisation(True)\n",
    "            self.lo_Norm = Normalisation(False)\n",
    "        self.weight_hi = nn.Parameter(torch.Tensor(1,1,kernel_size))\n",
    "        self.weight_lo = nn.Parameter(torch.Tensor(1,1,kernel_size))\n",
    "        \n",
    "        self.weights = []\n",
    "        self.weights.append(self.weight_hi) \n",
    "        for i in range(1,num_layers):\n",
    "            self.weights.append(torch.Tensor(1,1,kernel_size*(2**i)))\n",
    "        self.weights.append(torch.Tensor(1,1,kernel_size*2**(num_layers-1)))\n",
    "        \n",
    "        self.weights_dec = copy.deepcopy(self.weights)\n",
    "        \n",
    "        self.reset_parameters()\n",
    "\n",
    "# # Из фильтра высоких частот        \n",
    "    def reset_parameters(self):\n",
    "        nn.init.xavier_uniform_(self.weight_hi)\n",
    "#         nn.init.uniform_(self.weight_lo)\n",
    "#         self.weight_lo = nn.Parameter(torch.tensor([[[1,1]]], dtype=torch.float32))\n",
    "#         self.weight_hi = nn.Parameter(torch.tensor([[[0,-0.48296291314469025,0.836516303737469, \\\n",
    "#                         -0.22414386804185735,-0.12940952255092145,0]]], dtype=torch.float32))\n",
    "        weight_hi = self.weight_hi-self.weight_hi.mean()\n",
    "        self.weight_hi = nn.Parameter(weight_hi/torch.sqrt(self.energy(weight_hi)))\n",
    "        idx = torch.arange(self.weight_lo.size(2)-1, -1, -1).long()\n",
    "        weight_lo = self.weight_hi[:,:,idx]\n",
    "        odd = torch.arange(1, self.weight_lo.size(2), 2).long()\n",
    "        weight_lo[:,:,odd] = weight_lo[:,:,odd]*-1\n",
    "        self.weight_lo = nn.Parameter(weight_lo)\n",
    "\n",
    "        \n",
    "    def energy(self, tensor):\n",
    "        return (tensor.pow(2).sum())\n",
    "    \n",
    "    def upsample(self, weigth, filt, filt_rec):\n",
    "        kernel_size = weigth.shape[-1]\n",
    "        filt_size = filt.shape[-1]\n",
    "        upsampeled = torch.zeros((1,1,kernel_size*2-1)).cuda() #cuda does't implements automaticly \n",
    "    \n",
    "        upsampeled[:,:,::2] = weigth\n",
    "        upsampeled_pad = F.pad(upsampeled,(math.ceil(filt_size/2),math.floor(filt_size/2))) #padding\n",
    "#         upsampeled_pad = F.pad(upsampeled,(filt_size-1,filt_size-1)) #padding\n",
    "        idx = torch.arange(upsampeled_pad.size(2)-1, -1, -1).long()\n",
    "        return upsampeled, F.conv1d(upsampeled_pad, filt), F.conv1d(upsampeled_pad[:,:,idx], filt_rec)\n",
    "        \n",
    "    def reset_weights_enc(self, weight_lo, weight_hi):\n",
    "        self.weights[0] = weight_hi\n",
    "        idx = torch.arange(weight_hi.size(2)-1, -1, -1).long()\n",
    "        self.weights_dec[0] = weight_hi[:,:,idx]\n",
    "        last_lo = weight_lo\n",
    "        last_hi = weight_hi\n",
    "#         print (self.energy(self.weight_lo), self.energy(self.weight_hi), self.energy(last_lo) , self.energy(last_hi) )\n",
    "        accumulated_lo = weight_lo\n",
    "        accumulated_lo_dec = weight_lo[:,:,idx]\n",
    "        \n",
    "        for i in range(1,self.num_layers):\n",
    "            last_hi, self.weights[i], self.weights_dec[i] = self.upsample(last_hi, accumulated_lo,\n",
    "                                                                        accumulated_lo_dec)\n",
    "            last_lo, accumulated_lo, accumulated_lo_dec = self.upsample(last_lo, accumulated_lo,\n",
    "                                                                        accumulated_lo_dec)\n",
    "        self.weights[self.num_layers] = accumulated_lo\n",
    "        self.weights_dec[self.num_layers] = accumulated_lo_dec\n",
    "        if self.disp:\n",
    "            for w in self.weights[:]:\n",
    "                print (self.energy(w.data))\n",
    "#                 plt.plot(np.linspace(0,1,w.size(2)),w.data.numpy()[0,0,:])\n",
    "        \n",
    "    def reset_weights_dec(self):\n",
    "        for i,weight in enumerate(self.weights):            \n",
    "            inv_idx = torch.arange(weight.size(2)-1, -1, -1).long()\n",
    "            self.weights_dec[i] = weight[:,:,inv_idx]\n",
    "#         for w in self.weights_dec:\n",
    "#             print (w)\n",
    "\n",
    "\n",
    "    def encoding(self,data):\n",
    "        if self.norm:\n",
    "            weight_hi = self.hi_Norm(self.weight_hi)\n",
    "            weight_lo = self.lo_Norm(self.weight_lo)\n",
    "            self.reset_weights_enc(weight_hi,weight_lo)\n",
    "        else:\n",
    "            self.reset_weights_enc(self.weight_hi,self.weight_lo)\n",
    "        encoding = torch.Tensor(data.size(0),self.num_layers+1,data.size(2)).cuda()\n",
    "        for i,weight in enumerate(self.weights):\n",
    "            filt_size = weight.size(2)-1\n",
    "            left = math.ceil(filt_size/2)\n",
    "            rigth = math.floor(filt_size/2)\n",
    "#             print (i,F.conv1d(F.pad(data,(left,rigth)), weight))\n",
    "            encoding[:,i,:] = F.conv1d(F.pad(data,(left,rigth)), weight).squeeze(1)\n",
    "        return encoding\n",
    "    \n",
    "    def decoding(self,encoding):\n",
    "#         self.reset_weights_dec()\n",
    "        decoding = torch.zeros((encoding.size(0),1,encoding.size(2))).cuda()\n",
    "        for i,weight in enumerate(self.weights_dec):\n",
    "            filt_size = weight.size(2)-1\n",
    "            left = math.floor(filt_size/2)\n",
    "            rigth = math.ceil(filt_size/2)\n",
    "#             tmp = F.conv1d(F.pad(encoding[:,i,:].unsqueeze(1),(left,rigth)), weight)\n",
    "#             print (i, tmp)\n",
    "            decoding += F.conv1d(F.pad(encoding[:,i,:].unsqueeze(1),(left,rigth)), weight)\n",
    "#             print (F.conv1d(F.pad(encoding[:,i,:].unsqueeze(1),(left,rigth)), weight))\n",
    "        return decoding\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self,data):\n",
    "        if self.norm:\n",
    "            weight_hi = self.hi_Norm(self.weight_hi)\n",
    "            weight_lo = self.lo_Norm(self.weight_lo)\n",
    "            self.reset_weights_enc(weight_hi,weight_lo)\n",
    "        else:\n",
    "            self.reset_weights_enc(self.weight_hi,self.weight_lo)\n",
    "        encoding = torch.Tensor(data.size(0),self.num_layers+1,data.size(2)).cuda()\n",
    "        for i,weight in enumerate(self.weights):\n",
    "            filt_size = weight.size(2)-1\n",
    "            left = math.ceil(filt_size/2)\n",
    "            rigth = math.floor(filt_size/2)\n",
    "            encoding[:,i,:] = F.conv1d(F.pad(data,(left,rigth)), weight).squeeze(1)\n",
    "        return encoding\n",
    "        \n",
    "        \n",
    "\n",
    "#     def forward(self, input):\n",
    "#         return F.conv1d(input, self.weight, self.bias, self.stride,\n",
    "#                         self.padding, self.dilation, self.groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(396.4082, device='cuda:0', grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "source": [
    "filters = torch.randn(1, 1, 10)\n",
    "inputs = torch.tensor([[[256,45,78,14,98,11,214,657,11,125]]], dtype=torch.float32).cuda()\n",
    "n = 4\n",
    "model = Wavelet(n, 6, disp = False).cuda()\n",
    "encod = model.encoding(inputs)\n",
    "dec = model.decoding(encod)\n",
    "print (torch.abs(inputs-dec).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2378,  0.6000,  0.4792,  0.2387, -0.4408,  0.9091,  0.5044,\n",
       "           0.3543, -0.2954,  0.3769,  0.0326,  0.2138]]],\n",
       "       device='cuda:0', grad_fn=<ThAddBackward>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "filt_1 = model.weights[1]\n",
    "_filt_1 = model.weights_dec[1]\n",
    "\n",
    "filt_size = filt_1.size(2)-1\n",
    "left = math.ceil(filt_size/2)\n",
    "rigth = math.floor(filt_size/2)\n",
    "full_filt = F.conv1d(F.pad(inputs,(left,rigth)), filt_1)\n",
    "\n",
    "F.conv1d(F.pad(filt_1,(left,rigth)), _filt_1) + \\\n",
    "F.conv1d(F.pad(model.weights[0],(left,rigth)), model.weights_dec[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[[-0.6535, -0.5301,  0.2206, -0.0335, -0.4071, -0.2764]]],\n",
       "        device='cuda:0', requires_grad=True),\n",
       " tensor([[[ 0.2023, -0.3029,  0.0050, -0.0815,  0.2864, -0.1569,  0.1689,\n",
       "           -0.1559,  0.1045, -0.1695,  0.1047, -0.1218]]],\n",
       "        device='cuda:0', grad_fn=<SqueezeBackward1>))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights[0], model.weights[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# model = Wavelet(n,12).cuda()\n",
    "# encod = model(inputs)\n",
    "# hi,lo = model.hi_Norm(model.weight_hi), model.lo_Norm(model.weight_lo)\n",
    "# print (F.sigmoid(model.hi_Norm.L), F.sigmoid(model.hi_Norm.B))\n",
    "# idx = torch.arange(hi.size(2)-1, -1, -1).long()\n",
    "# hi_f,lo_f = fft(hi[0,0,idx].cpu().data.numpy()), fft(lo[0,0,idx].cpu().data.numpy())\n",
    "# n = hi_f.shape[-1]\n",
    "# plt.plot(range(n//2),hi_f[:n//2])\n",
    "# plt.plot(range(n//2),lo_f[:n//2]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_splits = [1,2,3,4]\n",
    "test_split = 5\n",
    "\n",
    "shared_params = {'csv_path': '/home/ilya/workspace/ESC-50/esc50.csv',\n",
    "                 'wav_dir': '/home/ilya/workspace/ESC-50/audio',\n",
    "                 'dest_dir': '/home/ilya/workspace/ESC-50/audio/16000',\n",
    "                 'audio_rate': 16000,\n",
    "                 'only_ESC10': True,\n",
    "                 'pad': 0,\n",
    "                 'normalize': True}\n",
    "\n",
    "train_gen = ESC50(folds=train_splits,\n",
    "                  randomize=True,\n",
    "                  strongAugment=True,\n",
    "                  random_crop=True,\n",
    "                  inputLength=2,\n",
    "                  mix=False,\n",
    "                  **shared_params).batch_gen(16)\n",
    "\n",
    "test_gen = ESC50(folds=[test_split],\n",
    "                 randomize=False,\n",
    "                 strongAugment=False,\n",
    "                 random_crop=False,\n",
    "                 inputLength=4,\n",
    "                 mix=False,\n",
    "                 **shared_params).batch_gen(16)\n",
    "\n",
    "# X, Y = next(test_gen)\n",
    "# X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class classifier(nn.Module):\n",
    "    def __init__(self, wavelet_num_layers, wavelet_kernel_size, stride=1,\n",
    "                 padding=1, dilation=1, groups=1,disp = False, norm=True):\n",
    "        super(classifier, self).__init__()\n",
    "        self.wavelet_num_layers = wavelet_num_layers\n",
    "        self.wavelet_kernel_size = wavelet_kernel_size\n",
    "        \n",
    "        \n",
    "        self.wavelet = Wavelet(wavelet_num_layers, wavelet_kernel_size, disp=disp, norm=norm)\n",
    "        self.conv1 = nn.Conv1d(wavelet_num_layers+1, 15, 3)\n",
    "        self.pool = nn.MaxPool1d(2)\n",
    "        self.conv2 = nn.Conv1d(15,20,3)\n",
    "        self.conv3 = nn.Conv1d(20,25,3)\n",
    "        self.lastpool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc1 = nn.Linear(25,120)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(120,10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        encoded_x = self.wavelet(x)\n",
    "        output = self.pool(self.conv1(encoded_x))\n",
    "        output = self.pool(self.conv2(output))\n",
    "        output = self.conv3(output)\n",
    "        output = self.lastpool(output)\n",
    "        output = self.relu(self.fc1(output.squeeze()))\n",
    "        output = self.fc2(output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "classifier(\n",
       "  (wavelet): Wavelet()\n",
       "  (conv1): Conv1d(5, 15, kernel_size=(3,), stride=(1,))\n",
       "  (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv1d(15, 20, kernel_size=(3,), stride=(1,))\n",
       "  (conv3): Conv1d(20, 25, kernel_size=(3,), stride=(1,))\n",
       "  (lastpool): AdaptiveAvgPool1d(output_size=1)\n",
       "  (fc1): Linear(in_features=25, out_features=120, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=120, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = classifier(4, 8, disp=False, norm=False)\n",
    "net.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer_train = SummaryWriter()\n",
    "def criterion(outputs, labels, w_hi, w_lo, C, l2):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    loss = (w_hi.pow(2).sum()-1).pow(2)+(w_lo.pow(2).sum()-1).pow(2)\n",
    "    CrossEntropy = criterion(outputs, labels)\n",
    "    return (CrossEntropy+C*loss+l2*w_hi.sum().pow(2), loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(net.parameters(), lr=0.013957830839232406, momentum=0.99)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.7,patience=300, verbose=True, threshold=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 tensor(1.2367, device='cuda:0', grad_fn=<SumBackward0>) tensor(1.1125, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.5862, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.7062, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilya/anaconda3/envs/torch/lib/python3.6/site-packages/numpy/core/numeric.py:501: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 100 tensor(1.1722, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.9603, device='cuda:0', grad_fn=<SumBackward0>) tensor(1.4654, device='cuda:0', grad_fn=<SumBackward0>) tensor(2.5290, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 200 tensor(nan, device='cuda:0', grad_fn=<SumBackward0>) tensor(nan, device='cuda:0', grad_fn=<SumBackward0>) tensor(nan, device='cuda:0', grad_fn=<SumBackward0>) tensor(nan, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 0\n",
    "C = 0.1\n",
    "l2 = 0.03\n",
    "for epoch in range(100):  # loop over the dataset multiple times\n",
    "    \n",
    "    train_gen = ESC50(folds=train_splits,\n",
    "                  randomize=True,\n",
    "                  strongAugment=True,\n",
    "                  random_crop=True,\n",
    "                  inputLength=2,\n",
    "                  mix=False,\n",
    "                  **shared_params).batch_gen(128)\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_gen:\n",
    "        # get the inputs\n",
    "        inputs, labels = torch.Tensor(inputs).transpose(1,2).cuda(), torch.LongTensor(labels).cuda()\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "\n",
    "        _, labels = torch.max(labels, 1)\n",
    "        \n",
    "        loss, en = criterion(outputs, labels, net.wavelet.weight_hi, net.wavelet.weight_lo, C, l2)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step(loss)\n",
    "        \n",
    "        acc = (outputs.max(1)[1]==labels).float().mean() \n",
    "\n",
    "            \n",
    "        if i%100 == 0:\n",
    "            \n",
    "#             inputs, labels = next(test_gen) \n",
    "#             inputs, labels = torch.Tensor(inputs).transpose(1,2).cuda(), torch.LongTensor(labels).cuda()\n",
    "            \n",
    "#             outputs = net(inputs)\n",
    "            \n",
    "#             _, predicted = torch.max(outputs, 1)\n",
    "#             _, labels = torch.max(labels, 1)\n",
    "            \n",
    "#             loss_t, CrossEntropy_t = criterion(outputs, labels, net.wavelet.weight_hi, net.wavelet.weight_lo, C, l2)\n",
    "            \n",
    "#             scheduler.step(loss_t)\n",
    "            \n",
    "#             writer_train.add_scalar(\"CrossEntropy_t\", CrossEntropy_t.item())\n",
    "#             \n",
    "            \n",
    "            if net.wavelet.norm:\n",
    "                hi,lo = net.wavelet.hi_Norm(net.wavelet.weight_hi), net.wavelet.lo_Norm(net.wavelet.weight_lo)\n",
    "                print (epoch,i,net.wavelet.energy(hi), net.wavelet.energy(lo), \\\n",
    "                       net.wavelet.hi_Norm.B, loss.data)\n",
    "            else:\n",
    "                hi,lo = net.wavelet.weight_hi, net.wavelet.weight_lo\n",
    "                print (epoch,i,net.wavelet.energy(hi), net.wavelet.energy(lo), \\\n",
    "                       hi.sum(), loss.data)\n",
    "                \n",
    "            idx = torch.arange(hi.size(2)-1, -1, -1).long()\n",
    "            hi_f,lo_f = fft(hi[0,0,idx].cpu().data.numpy()), fft(lo[0,0,idx].cpu().data.numpy())\n",
    "            n = hi_f.shape[-1]\n",
    "            plt.plot(range(n//2),hi_f[:n//2])\n",
    "            plt.plot(range(n//2),lo_f[:n//2])\n",
    "            plt.show()\n",
    "        i+=1\n",
    "#         print (net.wavelet.energy(net.wavelet.weight_lo), net.wavelet.energy(net.wavelet.weight_hi), net.wavelet.lo_Norm.L.grad, loss.data)\n",
    "\n",
    "        writer_train.add_scalar(\"loss\", loss.item())\n",
    "        writer_train.add_scalar(\"en\", en.item())\n",
    "        writer_train.add_scalar(\"acc\", acc.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'params': [Parameter containing:\n",
       "   tensor([[[ 0.8245,  0.3279,  0.0917,  0.0243,  0.2557, -0.1015, -0.3932,\n",
       "             -0.4529]]], device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[[-0.0379, -0.7508, -0.3678, -0.4542, -0.3167, -0.3083,  0.0311,\n",
       "             -0.0978]]], device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[[ 0.5388,  1.0031,  0.8131],\n",
       "            [ 1.2152,  1.7535,  1.6769],\n",
       "            [-0.7824, -0.4636,  0.0754],\n",
       "            [ 0.4473,  1.0109,  0.4868],\n",
       "            [ 0.0904, -0.1610,  0.1406]],\n",
       "   \n",
       "           [[ 0.0781,  0.8424,  1.0107],\n",
       "            [ 0.2150,  0.7882, -0.4631],\n",
       "            [ 0.0950,  2.6695,  1.9845],\n",
       "            [ 0.7469,  1.9074,  0.8858],\n",
       "            [-0.2384, -1.3444, -1.4282]],\n",
       "   \n",
       "           [[-0.0533, -0.1215,  0.1628],\n",
       "            [ 0.5452,  0.6947,  0.6217],\n",
       "            [-0.6382, -0.3403, -0.1539],\n",
       "            [ 0.3595,  0.5687,  0.7305],\n",
       "            [ 0.0398,  0.0433, -0.5629]],\n",
       "   \n",
       "           [[ 0.1608,  0.2690,  0.7942],\n",
       "            [ 0.8559,  1.1740,  1.1667],\n",
       "            [-0.9922, -1.0110, -0.7378],\n",
       "            [-0.3205, -0.1251,  0.2087],\n",
       "            [ 0.7267,  0.8068,  0.9601]],\n",
       "   \n",
       "           [[-0.3825, -1.0104, -0.9417],\n",
       "            [-0.9855, -1.4206, -0.8866],\n",
       "            [-0.1569, -0.8546, -0.9313],\n",
       "            [-0.0219, -0.5831, -0.4998],\n",
       "            [-0.3964, -0.1223,  0.2001]],\n",
       "   \n",
       "           [[-0.2372,  0.2361,  0.4615],\n",
       "            [ 0.5353,  1.3678,  1.5800],\n",
       "            [-0.9053, -0.7991, -0.3004],\n",
       "            [-0.8194, -0.3529,  0.3876],\n",
       "            [ 0.7408, -0.1398, -0.1819]],\n",
       "   \n",
       "           [[ 0.3520,  0.8610,  0.8589],\n",
       "            [ 0.1848,  0.8635, -0.1265],\n",
       "            [ 0.3449,  3.1735,  2.8602],\n",
       "            [ 2.3401,  2.6919,  1.1547],\n",
       "            [-1.4122, -1.7047, -1.8358]],\n",
       "   \n",
       "           [[ 0.4964,  0.7972,  0.5800],\n",
       "            [ 0.8407,  0.8991, -0.0108],\n",
       "            [ 0.2887,  1.4085,  0.6611],\n",
       "            [ 1.2149,  1.2650,  0.0402],\n",
       "            [ 0.2382,  0.4112,  0.6250]],\n",
       "   \n",
       "           [[ 0.4758,  1.1586,  1.0693],\n",
       "            [ 1.3662,  1.6901,  1.2603],\n",
       "            [-0.5581,  0.3303, -0.0254],\n",
       "            [-0.5819, -0.0680, -0.1921],\n",
       "            [ 0.9530,  0.6856,  1.2568]],\n",
       "   \n",
       "           [[-0.5078, -0.6845, -0.8543],\n",
       "            [-0.7393, -1.0737, -0.7053],\n",
       "            [ 0.4199, -0.1339, -0.4041],\n",
       "            [ 0.1969,  0.2226, -0.0504],\n",
       "            [ 0.1428, -0.1668, -0.2307]],\n",
       "   \n",
       "           [[-0.2197, -0.8441, -0.6943],\n",
       "            [-0.5992, -0.6453, -0.3607],\n",
       "            [ 0.2733,  0.0009, -0.3732],\n",
       "            [ 0.1507,  0.0071,  0.3528],\n",
       "            [-0.5119, -0.2347, -0.8538]],\n",
       "   \n",
       "           [[ 0.0218,  1.3395,  1.6080],\n",
       "            [ 0.8623,  1.2816,  0.4434],\n",
       "            [ 0.5027,  3.3550,  2.7134],\n",
       "            [ 1.3569,  2.0574,  1.2049],\n",
       "            [-0.3552, -1.4215, -1.8104]],\n",
       "   \n",
       "           [[ 0.0912, -0.0012,  0.1085],\n",
       "            [-0.2235,  0.0339,  0.1659],\n",
       "            [ 0.2893, -0.1768, -0.1282],\n",
       "            [ 0.3803, -0.1441, -0.1108],\n",
       "            [-0.3712, -0.0286, -0.2576]],\n",
       "   \n",
       "           [[ 0.2692,  0.0038, -0.1068],\n",
       "            [ 0.1093, -0.5108, -0.3802],\n",
       "            [ 0.6069,  0.7627,  0.5750],\n",
       "            [ 0.4037,  0.5289,  0.1614],\n",
       "            [-0.4493, -0.4802, -0.9264]],\n",
       "   \n",
       "           [[ 0.2321,  0.5998,  0.9696],\n",
       "            [ 0.6966,  0.5585,  0.6621],\n",
       "            [-0.4421, -0.0653,  0.1293],\n",
       "            [-0.0712,  0.5541,  0.3138],\n",
       "            [ 0.1029, -0.0619,  0.0738]]], device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([-0.0248, -0.0107, -0.0065, -0.0143, -0.0151, -0.0213, -0.0282, -0.0084,\n",
       "           -0.0189, -0.0157, -0.0181, -0.0179,  0.0015, -0.0107, -0.0056],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[[ 0.3564,  0.7258,  0.3769],\n",
       "            [-0.9134, -0.0627,  0.4720],\n",
       "            [ 0.2351,  0.4289, -0.1868],\n",
       "            [ 0.6810,  0.7513,  0.1246],\n",
       "            [ 0.2718, -0.4483, -0.8479],\n",
       "            [ 0.5882,  0.5214,  0.0470],\n",
       "            [-0.9951, -0.0897,  0.6532],\n",
       "            [-0.2785,  0.3340,  0.5876],\n",
       "            [ 0.3699,  0.5711,  0.8178],\n",
       "            [-0.0807, -0.3342, -0.5557],\n",
       "            [-0.0619, -0.3369, -0.4588],\n",
       "            [-0.8267,  0.1439,  1.1947],\n",
       "            [ 0.0758, -0.1096,  0.0650],\n",
       "            [-0.5545, -0.3579,  0.0515],\n",
       "            [ 0.0274,  0.4267,  0.4150]],\n",
       "   \n",
       "           [[ 0.0796,  0.2221,  0.0308],\n",
       "            [ 0.5145, -0.4652,  0.3103],\n",
       "            [-0.0076,  0.1406, -0.0031],\n",
       "            [ 0.1404,  0.2337, -0.0339],\n",
       "            [ 0.0817,  0.1028,  0.0568],\n",
       "            [ 0.2600,  0.0704, -0.1657],\n",
       "            [ 0.4600, -0.8526,  0.4943],\n",
       "            [-0.0478, -0.4058,  0.1661],\n",
       "            [ 0.1684, -0.1450,  0.0127],\n",
       "            [-0.0979, -0.0513, -0.0412],\n",
       "            [-0.0856,  0.2018, -0.0094],\n",
       "            [ 0.3698, -0.8805,  0.3407],\n",
       "            [ 0.0837, -0.0496, -0.0334],\n",
       "            [ 0.0099, -0.0565,  0.0203],\n",
       "            [ 0.1873, -0.0392,  0.0026]],\n",
       "   \n",
       "           [[-0.0730,  0.0007,  0.0994],\n",
       "            [ 0.0189,  0.3644,  0.2124],\n",
       "            [ 0.0083,  0.0626,  0.0335],\n",
       "            [-0.2753, -0.1971, -0.3504],\n",
       "            [-0.0926, -0.0980, -0.1911],\n",
       "            [-0.2997, -0.0756,  0.1044],\n",
       "            [ 0.5361,  0.6351,  0.4647],\n",
       "            [-0.0320,  0.1805, -0.1801],\n",
       "            [-0.4500, -0.2829, -0.4513],\n",
       "            [ 0.0507,  0.0478, -0.0434],\n",
       "            [ 0.2225,  0.1471,  0.2753],\n",
       "            [ 0.3179,  0.4730,  0.3673],\n",
       "            [ 0.1352,  0.0707,  0.1267],\n",
       "            [ 0.0527,  0.2777,  0.1969],\n",
       "            [ 0.0187,  0.0194, -0.0494]],\n",
       "   \n",
       "           [[-0.7087, -0.4394,  0.0037],\n",
       "            [ 0.0611, -0.0957, -0.0292],\n",
       "            [-0.3029,  0.0251,  0.0682],\n",
       "            [-0.5560, -0.3338, -0.1719],\n",
       "            [ 0.2962,  0.5694,  0.3858],\n",
       "            [-0.5543, -0.2396,  0.0309],\n",
       "            [ 0.1175,  0.0686, -0.0912],\n",
       "            [-0.1733, -0.3558, -0.3189],\n",
       "            [-0.6182, -0.6417, -0.3559],\n",
       "            [ 0.4853,  0.3583,  0.2336],\n",
       "            [ 0.3538,  0.2640,  0.4393],\n",
       "            [-0.1497, -0.1894, -0.3973],\n",
       "            [-0.1057,  0.0491,  0.0640],\n",
       "            [ 0.1411,  0.0658,  0.0921],\n",
       "            [-0.3055, -0.3546, -0.0329]],\n",
       "   \n",
       "           [[ 0.0112, -0.1731, -0.2295],\n",
       "            [ 0.1993,  0.2673,  0.1181],\n",
       "            [-0.1161, -0.0676, -0.2628],\n",
       "            [-0.0615, -0.2871, -0.1193],\n",
       "            [-0.2644, -0.2420, -0.1471],\n",
       "            [-0.0894, -0.2535, -0.3105],\n",
       "            [ 0.1949,  0.1067,  0.1779],\n",
       "            [-0.0407,  0.1347,  0.2152],\n",
       "            [ 0.0543,  0.1163,  0.0242],\n",
       "            [-0.0758,  0.0254, -0.0479],\n",
       "            [-0.0302, -0.1837,  0.1498],\n",
       "            [ 0.0616,  0.3238,  0.1622],\n",
       "            [-0.0740, -0.0328,  0.0634],\n",
       "            [ 0.1059,  0.1248,  0.2163],\n",
       "            [ 0.0726, -0.0673, -0.0959]],\n",
       "   \n",
       "           [[ 0.1746,  0.2790, -0.6114],\n",
       "            [-0.3712,  0.5290, -0.3612],\n",
       "            [ 0.1420,  0.0572, -0.3194],\n",
       "            [ 0.2341, -0.0332, -0.4053],\n",
       "            [ 0.0080, -0.3312,  0.3650],\n",
       "            [ 0.2293,  0.0150, -0.3285],\n",
       "            [-0.3571,  0.6492, -0.5613],\n",
       "            [ 0.0007,  0.4048, -0.1082],\n",
       "            [ 0.1718,  0.0418, -0.3104],\n",
       "            [-0.1234, -0.1340,  0.1190],\n",
       "            [-0.1706, -0.1152,  0.2036],\n",
       "            [-0.3858,  0.6559, -0.2826],\n",
       "            [ 0.0534, -0.1351,  0.1159],\n",
       "            [-0.1411,  0.0959,  0.0617],\n",
       "            [ 0.2159,  0.2156, -0.3656]],\n",
       "   \n",
       "           [[-0.9553, -0.8830, -0.7613],\n",
       "            [ 0.2177, -0.1150, -0.3012],\n",
       "            [-0.4635, -0.3838,  0.0431],\n",
       "            [-0.7571, -0.5765, -0.5535],\n",
       "            [ 0.3828,  0.5948,  0.9684],\n",
       "            [-0.9495, -0.7310, -0.3284],\n",
       "            [ 0.1337, -0.1955, -0.2638],\n",
       "            [ 0.0312, -0.3624, -0.6176],\n",
       "            [-0.7583, -0.9963, -1.0832],\n",
       "            [ 0.5450,  0.6854,  0.5781],\n",
       "            [ 0.2440,  0.4543,  0.4981],\n",
       "            [-0.1372, -0.5400, -0.8865],\n",
       "            [ 0.0866,  0.0048, -0.0140],\n",
       "            [ 0.3697,  0.2054,  0.1183],\n",
       "            [-0.4710, -0.4491, -0.2887]],\n",
       "   \n",
       "           [[-0.0095,  0.0288, -0.0517],\n",
       "            [ 0.1916,  0.5330,  0.3494],\n",
       "            [-0.1603, -0.0857,  0.3551],\n",
       "            [-0.3243, -0.3863, -0.3820],\n",
       "            [-0.0257, -0.2344, -0.2203],\n",
       "            [-0.5807, -0.2580,  0.0773],\n",
       "            [ 0.8005,  1.0516,  0.6046],\n",
       "            [ 0.3284,  0.3108, -0.1879],\n",
       "            [-0.3139, -0.2252, -0.3825],\n",
       "            [ 0.0802, -0.1052,  0.0909],\n",
       "            [ 0.1106,  0.0820,  0.1919],\n",
       "            [ 0.3578,  0.8305,  0.7223],\n",
       "            [ 0.1673, -0.0383,  0.0499],\n",
       "            [ 0.3067,  0.3373,  0.2785],\n",
       "            [-0.1587, -0.0272, -0.1398]],\n",
       "   \n",
       "           [[-0.0515, -0.1173, -0.0708],\n",
       "            [-0.2649, -1.2459, -0.7001],\n",
       "            [ 0.0975, -0.1803, -0.3266],\n",
       "            [ 0.6456,  0.6321,  0.3869],\n",
       "            [-0.1734,  0.4302,  0.2312],\n",
       "            [ 0.7566,  0.4210, -0.3826],\n",
       "            [-1.4467, -1.6077, -1.1025],\n",
       "            [-0.4228, -0.3571,  0.3326],\n",
       "            [ 0.5882,  0.3499,  0.7531],\n",
       "            [ 0.0078, -0.0173, -0.1057],\n",
       "            [-0.2138, -0.0337, -0.4456],\n",
       "            [-0.7207, -1.4137, -1.1107],\n",
       "            [-0.3948,  0.1786, -0.1588],\n",
       "            [-0.3745, -0.4842, -0.4987],\n",
       "            [ 0.0300,  0.0904,  0.0475]],\n",
       "   \n",
       "           [[ 1.2814,  0.1685, -1.2332],\n",
       "            [ 0.4797,  0.0921, -0.7655],\n",
       "            [ 0.4148,  0.0284, -0.2683],\n",
       "            [ 0.9763, -0.2137, -0.5358],\n",
       "            [-0.8200,  0.1303,  0.8545],\n",
       "            [ 0.6417, -0.2174, -0.3376],\n",
       "            [ 0.6361,  0.2562, -0.8843],\n",
       "            [ 0.7104,  0.3570, -1.0075],\n",
       "            [ 1.0814, -0.1493, -0.8470],\n",
       "            [-0.3960,  0.1221,  0.6728],\n",
       "            [-0.4881,  0.0270,  0.6150],\n",
       "            [ 0.9053, -0.1843, -1.1232],\n",
       "            [-0.0132,  0.0095, -0.0792],\n",
       "            [-0.2225,  0.3000, -0.0191],\n",
       "            [ 0.6892, -0.1698, -0.6695]],\n",
       "   \n",
       "           [[-0.1512, -0.0153, -0.1109],\n",
       "            [ 0.0178, -0.0028,  0.0195],\n",
       "            [ 0.0771,  0.0585,  0.0487],\n",
       "            [-0.1673, -0.0397, -0.1296],\n",
       "            [ 0.0162, -0.0578,  0.0019],\n",
       "            [-0.1201, -0.1940,  0.0511],\n",
       "            [ 0.0858,  0.0218, -0.0375],\n",
       "            [ 0.0300,  0.1009,  0.1412],\n",
       "            [-0.0668, -0.1487, -0.1789],\n",
       "            [-0.0327,  0.1190,  0.1835],\n",
       "            [ 0.1192,  0.0955, -0.0725],\n",
       "            [-0.1269, -0.0471,  0.0338],\n",
       "            [-0.0543,  0.0667, -0.1030],\n",
       "            [-0.1072, -0.0760,  0.1400],\n",
       "            [-0.0539, -0.0857, -0.0312]],\n",
       "   \n",
       "           [[ 0.2305,  0.3124,  0.2193],\n",
       "            [ 1.0623, -0.1185,  1.1024],\n",
       "            [ 0.4633,  0.1626,  0.1099],\n",
       "            [-0.1400, -0.0063, -0.3299],\n",
       "            [-0.2251,  0.3221, -0.4754],\n",
       "            [-0.1290, -0.0796,  0.3796],\n",
       "            [ 1.3755,  0.1599,  1.3919],\n",
       "            [ 0.5942, -0.4769, -0.0776],\n",
       "            [-0.1352, -0.2930, -0.1974],\n",
       "            [-0.0906,  0.0286, -0.2982],\n",
       "            [-0.0286,  0.2304, -0.0041],\n",
       "            [ 1.2541, -0.2126,  1.3212],\n",
       "            [ 0.0590,  0.1490, -0.0172],\n",
       "            [ 0.3506,  0.0438,  0.2340],\n",
       "            [ 0.2251,  0.0543,  0.2069]],\n",
       "   \n",
       "           [[-0.7147,  0.0851,  0.5087],\n",
       "            [-0.2525,  0.0151,  0.5610],\n",
       "            [-0.3408,  0.0739,  0.0709],\n",
       "            [-0.3324,  0.1798, -0.0346],\n",
       "            [ 0.4197,  0.0782, -0.2693],\n",
       "            [-0.1028,  0.2245, -0.0681],\n",
       "            [-0.4686, -0.2123,  0.5331],\n",
       "            [-0.4240, -0.3057,  0.1390],\n",
       "            [-0.4637, -0.1320,  0.2340],\n",
       "            [ 0.0437, -0.0419, -0.3044],\n",
       "            [ 0.1276, -0.1322, -0.0611],\n",
       "            [-0.6719,  0.0715,  0.5867],\n",
       "            [-0.0879,  0.0870,  0.1199],\n",
       "            [-0.0177, -0.0602,  0.0940],\n",
       "            [-0.2279,  0.0956,  0.3808]],\n",
       "   \n",
       "           [[ 0.4789,  0.2740,  0.0442],\n",
       "            [-0.0963, -0.0568,  0.0459],\n",
       "            [ 0.0158,  0.0456, -0.1803],\n",
       "            [ 0.4175,  0.1360,  0.2294],\n",
       "            [-0.3822, -0.4219, -0.4076],\n",
       "            [ 0.4497,  0.1461,  0.1815],\n",
       "            [-0.1605, -0.2084, -0.2222],\n",
       "            [ 0.0437,  0.0596,  0.2022],\n",
       "            [ 0.5082,  0.4876,  0.5629],\n",
       "            [-0.4062, -0.4017, -0.4370],\n",
       "            [-0.2593, -0.4028, -0.4405],\n",
       "            [ 0.1425,  0.1736,  0.1624],\n",
       "            [ 0.0808, -0.1131, -0.1107],\n",
       "            [-0.1778, -0.0068,  0.0393],\n",
       "            [ 0.1167,  0.1252,  0.1861]],\n",
       "   \n",
       "           [[-0.6533,  0.0457,  0.3166],\n",
       "            [-0.2262,  0.0969,  0.3294],\n",
       "            [-0.3808,  0.0121,  0.1813],\n",
       "            [-0.3580, -0.0625,  0.1753],\n",
       "            [ 0.4134, -0.1111, -0.3201],\n",
       "            [-0.1700, -0.0236,  0.1010],\n",
       "            [-0.4574, -0.1771,  0.4884],\n",
       "            [-0.4050, -0.1072,  0.3991],\n",
       "            [-0.4385,  0.1156,  0.1960],\n",
       "            [ 0.1845, -0.1650, -0.3550],\n",
       "            [ 0.2414, -0.1390, -0.2811],\n",
       "            [-0.5010,  0.0800,  0.5772],\n",
       "            [ 0.1006, -0.0467, -0.1055],\n",
       "            [-0.0731,  0.0834, -0.0123],\n",
       "            [-0.3283,  0.1256,  0.2533]],\n",
       "   \n",
       "           [[-0.4430, -0.0315,  0.0419],\n",
       "            [-1.2633,  2.3993, -1.2559],\n",
       "            [-0.1365, -0.1532,  0.0674],\n",
       "            [ 0.0042, -0.4930,  0.2213],\n",
       "            [ 0.3913, -0.6375,  0.0880],\n",
       "            [-0.4028, -0.2759,  0.3979],\n",
       "            [-1.2293,  2.8492, -1.7179],\n",
       "            [-0.3994,  1.0664, -0.6102],\n",
       "            [-0.3925,  0.3757, -0.0653],\n",
       "            [ 0.1505, -0.1167,  0.2153],\n",
       "            [ 0.0136, -0.3049,  0.2899],\n",
       "            [-1.7046,  2.9837, -1.2644],\n",
       "            [ 0.0698, -0.1527,  0.0806],\n",
       "            [-0.1774,  0.4363, -0.1209],\n",
       "            [-0.3140,  0.1372, -0.0974]],\n",
       "   \n",
       "           [[ 0.1279, -0.1629, -0.2927],\n",
       "            [ 0.1085,  0.1831, -0.0356],\n",
       "            [ 0.0028,  0.0062, -0.0404],\n",
       "            [ 0.0928,  0.0443, -0.0795],\n",
       "            [-0.1847, -0.0588, -0.0207],\n",
       "            [-0.0490, -0.1937, -0.2830],\n",
       "            [ 0.2242,  0.0534, -0.1376],\n",
       "            [ 0.0785,  0.3437,  0.2541],\n",
       "            [ 0.1680,  0.1542,  0.0871],\n",
       "            [-0.1362, -0.0131,  0.0424],\n",
       "            [-0.0294, -0.0502, -0.0693],\n",
       "            [ 0.1190,  0.2581, -0.0367],\n",
       "            [ 0.0397, -0.1005, -0.0936],\n",
       "            [ 0.0035, -0.1345,  0.0826],\n",
       "            [-0.0731, -0.1052, -0.1147]],\n",
       "   \n",
       "           [[ 0.0328, -0.0239,  0.0874],\n",
       "            [-0.2794, -0.7702, -0.3422],\n",
       "            [ 0.0439, -0.0965,  0.0044],\n",
       "            [ 0.2823,  0.2720,  0.1076],\n",
       "            [-0.1576,  0.2886,  0.2632],\n",
       "            [ 0.4391,  0.2076, -0.2221],\n",
       "            [-0.7331, -0.8525, -0.6379],\n",
       "            [-0.3137, -0.3004,  0.3262],\n",
       "            [ 0.1974,  0.0251,  0.2943],\n",
       "            [ 0.0342,  0.0840, -0.0545],\n",
       "            [ 0.0438, -0.1422, -0.3137],\n",
       "            [-0.3159, -0.7536, -0.6549],\n",
       "            [ 0.0020,  0.0389, -0.0905],\n",
       "            [-0.3152, -0.3151, -0.1812],\n",
       "            [-0.0302,  0.1536, -0.0784]],\n",
       "   \n",
       "           [[-0.0970, -0.0721, -0.1010],\n",
       "            [-0.4054, -0.0946, -0.3858],\n",
       "            [-0.0646, -0.0546, -0.2051],\n",
       "            [ 0.1225,  0.0972,  0.1931],\n",
       "            [ 0.1523,  0.1549,  0.1371],\n",
       "            [ 0.0978,  0.0430, -0.1225],\n",
       "            [-0.6315, -0.1677, -0.3683],\n",
       "            [-0.2506,  0.1773, -0.0245],\n",
       "            [ 0.0790,  0.1069,  0.0749],\n",
       "            [-0.0241, -0.0974,  0.1799],\n",
       "            [ 0.0582, -0.1458, -0.0537],\n",
       "            [-0.3821, -0.2680, -0.5824],\n",
       "            [-0.0117, -0.0413, -0.1675],\n",
       "            [-0.0738, -0.1490, -0.2274],\n",
       "            [ 0.0289, -0.0862, -0.1262]],\n",
       "   \n",
       "           [[ 0.5196,  0.5436,  0.3705],\n",
       "            [-0.2713, -0.1596,  0.2030],\n",
       "            [ 0.2402, -0.0165,  0.0526],\n",
       "            [ 0.4865,  0.2627,  0.0794],\n",
       "            [-0.0215, -0.3834, -0.7089],\n",
       "            [ 0.5183,  0.4729,  0.1849],\n",
       "            [-0.4003,  0.0185,  0.0839],\n",
       "            [-0.1013,  0.3050,  0.4911],\n",
       "            [ 0.3810,  0.6425,  0.7577],\n",
       "            [-0.1835, -0.1895, -0.5316],\n",
       "            [-0.1116, -0.1408, -0.2725],\n",
       "            [-0.2231,  0.1325,  0.5659],\n",
       "            [-0.0536,  0.0360, -0.0487],\n",
       "            [-0.2884, -0.1798,  0.0637],\n",
       "            [ 0.0478,  0.3248,  0.1073]]], device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([-0.0950, -0.0501, -0.0740, -0.1506, -0.0555, -0.0693, -0.1714, -0.0683,\n",
       "           -0.1510, -0.1362, -0.0210, -0.0950,  0.0316, -0.1280, -0.0393, -0.1263,\n",
       "            0.0282, -0.0537, -0.0899, -0.0912],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[[-0.1539, -0.1425, -0.1261],\n",
       "            [-0.2166, -0.0153,  0.0309],\n",
       "            [ 0.0445, -0.0459,  0.1267],\n",
       "            ...,\n",
       "            [ 0.0049, -0.0162, -0.0740],\n",
       "            [-0.1152,  0.0475, -0.0270],\n",
       "            [-0.0455, -0.0633, -0.0773]],\n",
       "   \n",
       "           [[-0.1866,  0.0401, -0.0405],\n",
       "            [-0.0077,  0.1453, -0.0183],\n",
       "            [ 0.0260, -0.1383,  0.0182],\n",
       "            ...,\n",
       "            [ 0.0492, -0.1111, -0.1417],\n",
       "            [ 0.1883,  0.0210,  0.1646],\n",
       "            [-0.0717, -0.0236, -0.1391]],\n",
       "   \n",
       "           [[-0.3975, -0.3652, -0.3820],\n",
       "            [ 0.0804,  0.0645,  0.1168],\n",
       "            [ 0.1596,  0.3144,  0.1867],\n",
       "            ...,\n",
       "            [ 0.1642,  0.2101,  0.1411],\n",
       "            [-0.1452, -0.0874,  0.0293],\n",
       "            [-0.3510, -0.2759, -0.1388]],\n",
       "   \n",
       "           ...,\n",
       "   \n",
       "           [[ 0.0452, -0.1427, -0.1790],\n",
       "            [-0.1268, -0.1336, -0.0865],\n",
       "            [ 0.3855,  0.2726,  0.3096],\n",
       "            ...,\n",
       "            [ 0.0130,  0.1586, -0.0006],\n",
       "            [-0.0260, -0.0760, -0.0699],\n",
       "            [ 0.0388, -0.0616, -0.0623]],\n",
       "   \n",
       "           [[-0.1404, -0.2829, -0.3160],\n",
       "            [ 0.1797, -0.0197,  0.1280],\n",
       "            [ 0.2315,  0.1914,  0.2235],\n",
       "            ...,\n",
       "            [ 0.3687,  0.3753,  0.4685],\n",
       "            [ 0.1382,  0.2269,  0.1855],\n",
       "            [-0.1393, -0.0110, -0.0782]],\n",
       "   \n",
       "           [[ 0.0007, -0.0947, -0.1195],\n",
       "            [-0.0949, -0.2136, -0.1174],\n",
       "            [-0.0235,  0.0629,  0.1899],\n",
       "            ...,\n",
       "            [-0.2222, -0.0922,  0.0037],\n",
       "            [ 0.0287, -0.0951, -0.0179],\n",
       "            [-0.0642,  0.0439, -0.1028]]], device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([ 0.0934, -0.1528, -0.0616, -0.0542,  0.2633,  0.5928,  0.4011,  0.1350,\n",
       "            0.2103,  0.1703, -0.6024, -0.2490, -0.1766,  0.4805, -0.2173, -0.1106,\n",
       "           -0.2855, -0.0295,  0.2124, -0.1447, -0.9476, -0.4947, -0.3027, -0.2259,\n",
       "           -0.5377], device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[ 0.1779, -0.1663,  0.0656,  ...,  0.0635, -0.3934,  0.2863],\n",
       "           [ 0.2293,  0.1836, -0.0152,  ...,  0.1960,  0.0872,  0.2061],\n",
       "           [ 0.2585,  0.1763,  0.1427,  ..., -0.1527, -0.1669,  0.0084],\n",
       "           ...,\n",
       "           [ 0.0980, -0.0942, -0.1348,  ...,  0.3106, -0.0616,  0.0580],\n",
       "           [ 0.4749,  0.0187,  0.0570,  ...,  0.1861,  0.0605,  0.1846],\n",
       "           [ 0.0922,  0.1313,  0.0754,  ..., -0.1286, -0.0979,  0.0108]],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([ 0.4662, -0.0364, -0.1552, -0.3237,  0.5748,  0.2038, -0.4697,  0.2904,\n",
       "            0.7427, -0.4477, -0.1899, -0.1855, -0.0203, -0.3905, -0.3638, -0.1389,\n",
       "            0.2280, -0.2709,  0.6468, -0.4255, -0.2094,  0.8622,  0.1790, -0.5298,\n",
       "           -0.2659, -0.1066, -0.4338, -0.3097,  0.2756, -0.6158,  0.2048,  0.5702,\n",
       "           -0.0512, -0.2429, -0.2384,  0.1513, -0.2115,  0.2886, -0.1155, -0.0125,\n",
       "           -0.2500,  0.0097, -0.2426, -0.1914, -0.3306,  0.0342,  0.1227, -0.4175,\n",
       "            0.6291,  0.5679, -0.2575,  0.8055, -0.0165, -0.3327, -0.2231,  0.5177,\n",
       "           -0.1695, -0.3716, -0.0010,  0.0059,  0.2936, -0.5420, -0.3549, -0.0554,\n",
       "            0.8998, -0.2378,  0.4133,  0.3609, -0.0346, -0.1853, -0.3241, -0.2583,\n",
       "            0.3479, -0.1160,  0.2946, -0.0719,  0.0409, -0.0643,  0.3805,  0.7076,\n",
       "            0.6591,  0.5795, -0.0704, -0.2539, -0.5181,  0.4678,  0.2712, -0.1160,\n",
       "            0.3172, -0.4125, -0.2981,  0.1105,  0.5234,  0.2281,  0.0567, -0.4132,\n",
       "            0.0251, -0.2568,  0.2984, -0.0691,  0.3534,  0.2336, -0.0420, -0.1609,\n",
       "            0.1574, -0.4631, -0.3627, -0.2871, -0.4137, -0.0788,  0.2001, -0.0665,\n",
       "            0.3696,  0.1303, -0.1436, -0.0992,  0.0619, -0.3135, -0.4607, -0.3091],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[-0.5247,  0.0929,  0.0299,  ..., -0.2997,  0.4762,  0.0426],\n",
       "           [-0.0230,  0.1539, -0.1356,  ...,  0.4308,  0.0557, -0.0905],\n",
       "           [ 0.2860, -0.1445,  0.0935,  ...,  0.1057, -0.1591,  0.0240],\n",
       "           ...,\n",
       "           [ 0.3200, -0.1898,  0.1738,  ...,  0.0553, -0.5633,  0.0547],\n",
       "           [ 0.3966, -0.0529,  0.1559,  ..., -0.1670,  0.1820,  0.0724],\n",
       "           [-0.4113, -0.0631, -0.0284,  ...,  0.2152, -0.0125,  0.0184]],\n",
       "          device='cuda:0', requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([-0.8759, -1.3608,  0.8680,  1.5122, -0.8099,  0.0287,  0.4071,  0.0145,\n",
       "            0.5393, -0.3717], device='cuda:0', requires_grad=True)],\n",
       "  'lr': 0.00013957830839232406,\n",
       "  'momentum': 0.9,\n",
       "  'dampening': 0,\n",
       "  'weight_decay': 0,\n",
       "  'nesterov': False}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "net.wavelet.hi_Norm.L, net.wavelet.hi_Norm(net.wavelet.weight_hi).pow(2).sum(), net.wavelet.weight_hi.pow(2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(),'test_save')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_load = classifier(4, 8, disp=False, norm=False)\n",
    "test_load.load_state_dict(torch.load('test_save'))\n",
    "test_load.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total = 0\n",
    "correct = 0\n",
    "train_gen = ESC50(folds=train_splits,\n",
    "                  randomize=True,\n",
    "                  strongAugment=True,\n",
    "                  random_crop=True,\n",
    "                  inputLength=2,\n",
    "                  mix=False,\n",
    "                  **shared_params).batch_gen(256)\n",
    "for inputs, labels in test_gen:\n",
    "        # get the inputs\n",
    "        inputs, labels = torch.Tensor(inputs).transpose(1,2).cuda(), torch.LongTensor(labels).cuda()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        _, labels = torch.max(labels, 1)\n",
    "        \n",
    "#         loss = criterion(outputs, labels, net.wavelet.weight_hi, net.wavelet.weight_lo, C, l2)\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for i in range(-100,100):\n",
    "    data.append(F.sigmoid(torch.Tensor([i]))-0.5)\n",
    "plt.plot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hi,lo = net.wavelet.weight_hi, net.wavelet.weight_lo\n",
    "idx = torch.arange(hi.size(2)-1, -1, -1).long()\n",
    "hi_f,lo_f = fft(hi[0,0,idx].cpu().data.numpy()), fft(lo[0,0,idx].cpu().data.numpy())\n",
    "n = hi_f.shape[-1]\n",
    "plt.plot(range(n//2),hi_f[:n//2])\n",
    "plt.plot(range(n//2),lo_f[:n//2]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 32000, 1)\n",
      "torch.Size([16, 1, 32000])\n"
     ]
    }
   ],
   "source": [
    "train_gen = ESC50(folds=train_splits,\n",
    "                  randomize=True,\n",
    "                  strongAugment=True,\n",
    "                  random_crop=True,\n",
    "                  inputLength=2,\n",
    "                  mix=False,\n",
    "                  **shared_params).batch_gen(16)\n",
    "inputs, labels = next(train_gen)\n",
    "print (inputs.shape)\n",
    "\n",
    "inputs, labels = torch.Tensor(inputs).transpose(1,2).cuda(), torch.LongTensor(labels).cuda()\n",
    "print (inputs.shape)\n",
    "stfts = torch.stft(inputs.squeeze(), n_fft=2047, hop_length=2047//2, win_length=2047, \\\n",
    "                   window=torch.hamming_window(2047).cuda(), center=False)\n",
    "ads_stfts = stfts.pow(2).sum(-1).sqrt()\n",
    "# model(inputs).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 1024, 30, 2]), torch.Size([16, 1024, 30]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stfts.shape, ads_stfts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class classifier_stft(nn.Module):\n",
    "    def __init__(self, n_fft, stride=1,padding=1, dilation=1, groups=1):\n",
    "        super(classifier_stft, self).__init__()\n",
    "        self.n_fft = n_fft\n",
    "        self.window = nn.Parameter(torch.hamming_window(self.n_fft), requires_grad=False)\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(30, 15, 3)\n",
    "        self.pool = nn.MaxPool1d(2)\n",
    "        self.conv2 = nn.Conv1d(15,20,3)\n",
    "        self.conv3 = nn.Conv1d(20,25,3)\n",
    "        self.lastpool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc1 = nn.Linear(25,120)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(120,10)\n",
    "\n",
    "    def stft(self,x):        \n",
    "        stfts = torch.stft(x.squeeze(), n_fft=self.n_fft, hop_length=self.n_fft//2, win_length=self.n_fft, \\\n",
    "                   window=self.window, center=False)\n",
    "        return stfts.pow(2).sum(-1).sqrt().transpose(1,2)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        encoded_x = self.stft(x)\n",
    "        output = self.pool(self.conv1(encoded_x))\n",
    "        output = self.pool(self.conv2(output))\n",
    "        output = self.conv3(output)\n",
    "        output = self.lastpool(output)\n",
    "        output = self.relu(self.fc1(output.squeeze()))\n",
    "        output = self.fc2(output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "classifier_stft(\n",
       "  (conv1): Conv1d(30, 15, kernel_size=(3,), stride=(1,))\n",
       "  (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv1d(15, 20, kernel_size=(3,), stride=(1,))\n",
       "  (conv3): Conv1d(20, 25, kernel_size=(3,), stride=(1,))\n",
       "  (lastpool): AdaptiveAvgPool1d(output_size=1)\n",
       "  (fc1): Linear(in_features=25, out_features=120, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=120, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_st = classifier_stft(2048)\n",
    "net_st.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(net_st.parameters(), lr=0.001, momentum=0.9)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.7,patience=100, verbose=True, threshold=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 tensor(0.8199, device='cuda:0') tensor(0.6797, device='cuda:0')\n",
      "0 100 tensor(0.7154, device='cuda:0') tensor(0.7422, device='cuda:0')\n",
      "Epoch   157: reducing learning rate of group 0 to 7.0000e-04.\n",
      "0 200 tensor(0.6816, device='cuda:0') tensor(0.7266, device='cuda:0')\n",
      "Epoch   258: reducing learning rate of group 0 to 4.9000e-04.\n",
      "0 300 tensor(0.6788, device='cuda:0') tensor(0.7109, device='cuda:0')\n",
      "Epoch   359: reducing learning rate of group 0 to 3.4300e-04.\n",
      "0 400 tensor(0.7895, device='cuda:0') tensor(0.7031, device='cuda:0')\n",
      "Epoch   481: reducing learning rate of group 0 to 2.4010e-04.\n",
      "0 500 tensor(0.8099, device='cuda:0') tensor(0.7500, device='cuda:0')\n",
      "Epoch   582: reducing learning rate of group 0 to 1.6807e-04.\n",
      "0 600 tensor(0.7526, device='cuda:0') tensor(0.6797, device='cuda:0')\n",
      "Epoch   683: reducing learning rate of group 0 to 1.1765e-04.\n",
      "0 700 tensor(0.6194, device='cuda:0') tensor(0.7500, device='cuda:0')\n",
      "Epoch   784: reducing learning rate of group 0 to 8.2354e-05.\n",
      "0 800 tensor(0.7446, device='cuda:0') tensor(0.7266, device='cuda:0')\n",
      "Epoch   885: reducing learning rate of group 0 to 5.7648e-05.\n",
      "0 900 tensor(0.6815, device='cuda:0') tensor(0.7812, device='cuda:0')\n",
      "Epoch   986: reducing learning rate of group 0 to 4.0354e-05.\n",
      "0 1000 tensor(0.5823, device='cuda:0') tensor(0.8125, device='cuda:0')\n",
      "Epoch  1087: reducing learning rate of group 0 to 2.8248e-05.\n",
      "0 1100 tensor(0.7035, device='cuda:0') tensor(0.7656, device='cuda:0')\n",
      "Epoch  1188: reducing learning rate of group 0 to 1.9773e-05.\n",
      "0 1200 tensor(0.7242, device='cuda:0') tensor(0.7578, device='cuda:0')\n",
      "Epoch  1289: reducing learning rate of group 0 to 1.3841e-05.\n",
      "0 1300 tensor(0.6870, device='cuda:0') tensor(0.7500, device='cuda:0')\n",
      "Epoch  1390: reducing learning rate of group 0 to 9.6889e-06.\n",
      "0 1400 tensor(0.5524, device='cuda:0') tensor(0.7812, device='cuda:0')\n",
      "Epoch  1491: reducing learning rate of group 0 to 6.7822e-06.\n",
      "0 1500 tensor(0.6388, device='cuda:0') tensor(0.7812, device='cuda:0')\n",
      "Epoch  1592: reducing learning rate of group 0 to 4.7476e-06.\n",
      "0 1600 tensor(0.6410, device='cuda:0') tensor(0.7188, device='cuda:0')\n",
      "0 1700 tensor(0.6457, device='cuda:0') tensor(0.7656, device='cuda:0')\n",
      "Epoch  1788: reducing learning rate of group 0 to 3.3233e-06.\n",
      "0 1800 tensor(0.5427, device='cuda:0') tensor(0.8203, device='cuda:0')\n",
      "Epoch  1889: reducing learning rate of group 0 to 2.3263e-06.\n",
      "0 1900 tensor(0.6388, device='cuda:0') tensor(0.7656, device='cuda:0')\n",
      "Epoch  1990: reducing learning rate of group 0 to 1.6284e-06.\n",
      "0 2000 tensor(0.6045, device='cuda:0') tensor(0.7656, device='cuda:0')\n",
      "Epoch  2091: reducing learning rate of group 0 to 1.1399e-06.\n",
      "0 2100 tensor(0.8231, device='cuda:0') tensor(0.6953, device='cuda:0')\n",
      "Epoch  2192: reducing learning rate of group 0 to 7.9792e-07.\n",
      "0 2200 tensor(0.6113, device='cuda:0') tensor(0.7500, device='cuda:0')\n",
      "Epoch  2293: reducing learning rate of group 0 to 5.5855e-07.\n",
      "0 2300 tensor(0.6673, device='cuda:0') tensor(0.7188, device='cuda:0')\n",
      "Epoch  2394: reducing learning rate of group 0 to 3.9098e-07.\n",
      "0 2400 tensor(0.6916, device='cuda:0') tensor(0.7500, device='cuda:0')\n",
      "Epoch  2495: reducing learning rate of group 0 to 2.7369e-07.\n",
      "0 2500 tensor(0.6489, device='cuda:0') tensor(0.7500, device='cuda:0')\n",
      "Epoch  2596: reducing learning rate of group 0 to 1.9158e-07.\n",
      "0 2600 tensor(0.6197, device='cuda:0') tensor(0.7266, device='cuda:0')\n",
      "Epoch  2697: reducing learning rate of group 0 to 1.3411e-07.\n",
      "0 2700 tensor(0.6437, device='cuda:0') tensor(0.7109, device='cuda:0')\n",
      "Epoch  2798: reducing learning rate of group 0 to 9.3875e-08.\n",
      "0 2800 tensor(0.6026, device='cuda:0') tensor(0.7344, device='cuda:0')\n",
      "Epoch  2899: reducing learning rate of group 0 to 6.5712e-08.\n",
      "0 2900 tensor(0.6439, device='cuda:0') tensor(0.7578, device='cuda:0')\n",
      "Epoch  3000: reducing learning rate of group 0 to 4.5999e-08.\n",
      "0 3000 tensor(0.7806, device='cuda:0') tensor(0.7344, device='cuda:0')\n",
      "0 3100 tensor(0.7141, device='cuda:0') tensor(0.7422, device='cuda:0')\n",
      "Epoch  3101: reducing learning rate of group 0 to 3.2199e-08.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-47599eab8c65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_gen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;31m# get the inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/ESC-50/utils.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Py3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Py2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/ESC-50/utils.py\u001b[0m in \u001b[0;36mbatch_gen\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m    208\u001b[0m                     \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m                     \u001b[0msound\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m                         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/ESC-50/utils.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Py3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Py2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/ESC-50/utils.py\u001b[0m in \u001b[0;36m_data_gen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0msound2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfname_to_wav\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0msound1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msound1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m                 \u001b[0msound2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msound2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m                 \u001b[0mlabel1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0mlabel2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/ESC-50/utils.py\u001b[0m in \u001b[0;36mpreprocess\u001b[0;34m(self, audio)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \"\"\"\n\u001b[1;32m    252\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_funcs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m             \u001b[0maudio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maudio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/ESC-50/bc_utils.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(sound)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfactor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msound\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msound\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "C = 0.07\n",
    "l2 = 0.03\n",
    "for epoch in range(100):  # loop over the dataset multiple times\n",
    "    \n",
    "    train_gen = ESC50(folds=train_splits,\n",
    "                  randomize=True,\n",
    "                  strongAugment=True,\n",
    "                  random_crop=True,\n",
    "                  inputLength=2,\n",
    "                  mix=False,\n",
    "                  **shared_params).batch_gen(128)\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_gen:\n",
    "        # get the inputs\n",
    "        inputs, labels = torch.Tensor(inputs).cuda(), torch.LongTensor(labels).cuda()\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        outputs = net_st(inputs)\n",
    "\n",
    "        _, labels = torch.max(labels, 1)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        scheduler.step(loss)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        if i%100 == 0:\n",
    "            test_gen\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            print (epoch,i,loss.data,(predicted==labels).float().mean()) \n",
    "                \n",
    "        i+=1\n",
    "#         print (net.wavelet.energy(net.wavelet.weight_lo), net.wavelet.energy(net.wavelet.weight_hi), net.wavelet.lo_Norm.L.grad, loss.data)\n",
    "        \n",
    "        writer.add_scalar(\"loss\", loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilya/anaconda3/envs/torch/lib/python3.6/site-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type classifier_stft. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(net_st,'stft')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
